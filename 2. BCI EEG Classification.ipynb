{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88e3d8a4",
   "metadata": {},
   "source": [
    "# EEG DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e016ab",
   "metadata": {},
   "source": [
    "The dimensions of the training set are as follows: 4,500 samples, 64 channels, and a time length of 795. This corresponds to 5 categories in y_train.\n",
    "\n",
    "The dimensions of the testing set are as follows: 750 samples, 64 channels, and a time length of 795. This corresponds to 5 categories in y_test.\n",
    "\n",
    "You can download it from this Google Drive link: [https://drive.google.com/drive/folders/1ykR-mn4d4KfFeeNrfR6UdtebsNRY8PU2?usp=sharing]. \n",
    "Please download the data and place it in your data_path at \"./data.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b284602d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fef2ddad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbb56c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(data_path + 'train_data.npy')\n",
    "test_data = np.load(data_path + 'test_data.npy')\n",
    "train_label = np.load(data_path + 'train_label.npy')\n",
    "test_label = np.load(data_path + 'test_label.npy')\n",
    "\n",
    "train_data_mean = np.mean(train_data)\n",
    "train_data_std = np.std(train_data)\n",
    "train_data_normalized = (train_data - train_data_mean) / train_data_std\n",
    "test_data_normalized = (test_data - train_data_mean) / train_data_std\n",
    "\n",
    "#To convert the data into PyTorch tensors\n",
    "x_train_tensor = torch.Tensor(train_data_normalized)\n",
    "y_train_tensor = torch.LongTensor(train_label)\n",
    "x_test_tensor = torch.Tensor(test_data_normalized)\n",
    "y_test_tensor = torch.LongTensor(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f13109bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #Setting GPU on your computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38430b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(x_train_tensor.to(device), y_train_tensor.to(device)) # input data to Tensor dataloader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, drop_last=True, shuffle=True) #  Batch size refers to the number of data sample\n",
    "test_dataset = TensorDataset(x_test_tensor.to(device), y_test_tensor.to(device))\n",
    "test_loader = DataLoader(test_dataset, batch_size=64,  drop_last=True,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a304b4d6",
   "metadata": {},
   "source": [
    "# Build simple Deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f9468f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGAutoencoderClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(EEGAutoencoderClassifier, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(64 * 795, 384), # Input dimention is 64 channel * 795 time point, and use 256 units for first NN layer\n",
    "            nn.BatchNorm1d(384),\n",
    "            nn.LeakyReLU(negative_slope=0.05), # Use LeakyReLu function for NN training \n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(384, 128), # 256 NN units to 192 units\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(negative_slope=0.05),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(128, 64),#  192 NN units to 128 units\n",
    "            nn.LeakyReLU(negative_slope=0.05)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64, num_classes), # num_classes is 5 (hello,” “help me,” “stop,” “thank you,” and “yes”)\n",
    "            nn.LogSoftmax(dim=1)  # Use LogSoftmax for multi-class classification\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.encoder(x)\n",
    "        \n",
    "        # import pdb;pdb.set_trace()\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2369fa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5 # setting final output class\n",
    "model = EEGAutoencoderClassifier(num_classes).to(device) \n",
    "criterion = nn.NLLLoss() # Use NLLLoss function to optimize\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) # Setting parameters learning rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "086a7e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Loss: 1.613937497138977\n",
      "Epoch 2/25, Loss: 1.5935986042022705\n",
      "Epoch 3/25, Loss: 1.6593667268753052\n",
      "Epoch 4/25, Loss: 1.6664403676986694\n",
      "Epoch 5/25, Loss: 1.4505765438079834\n",
      "Epoch 6/25, Loss: 1.3423374891281128\n",
      "Epoch 7/25, Loss: 1.2788554430007935\n",
      "Epoch 8/25, Loss: 1.3412023782730103\n",
      "Epoch 9/25, Loss: 1.1424118280410767\n",
      "Epoch 10/25, Loss: 1.0930392742156982\n",
      "Epoch 11/25, Loss: 1.1201082468032837\n",
      "Epoch 12/25, Loss: 0.8920886516571045\n",
      "Epoch 13/25, Loss: 0.8363171815872192\n",
      "Epoch 14/25, Loss: 0.8095013499259949\n",
      "Epoch 15/25, Loss: 0.8875225186347961\n",
      "Epoch 16/25, Loss: 0.6809893846511841\n",
      "Epoch 17/25, Loss: 0.6083361506462097\n",
      "Epoch 18/25, Loss: 0.6252530217170715\n",
      "Epoch 19/25, Loss: 0.5314902663230896\n",
      "Epoch 20/25, Loss: 0.5511147975921631\n",
      "Epoch 21/25, Loss: 0.39309418201446533\n",
      "Epoch 22/25, Loss: 0.59262615442276\n",
      "Epoch 23/25, Loss: 0.6370108723640442\n",
      "Epoch 24/25, Loss: 0.37889501452445984\n",
      "Epoch 25/25, Loss: 0.3389667868614197\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 25 # setting training epochs (Number of training iterations)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for data, labels in train_loader: \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7969f355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 48.44%\n"
     ]
    }
   ],
   "source": [
    "model.eval() # Evaluate your model\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, labels in test_loader:\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e64716d",
   "metadata": {},
   "source": [
    "This is to check what the best variables are to get the best accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d26740bb-a28e-42a4-811d-c87a9c589c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate = 0.5 and epoch = 5\n",
      "Epoch 1/5, Loss: 11.859838485717773\n",
      "Epoch 2/5, Loss: 2.453038454055786\n",
      "Epoch 3/5, Loss: 1.6721996068954468\n",
      "Epoch 4/5, Loss: 1.8306666612625122\n",
      "Epoch 5/5, Loss: 1.8097319602966309\n",
      "Test Accuracy: 20.17%\n",
      "Learning Rate = 0.5 and epoch = 10\n",
      "Epoch 1/10, Loss: 2.411003828048706\n",
      "Epoch 2/10, Loss: 1.965744137763977\n",
      "Epoch 3/10, Loss: 2.110834836959839\n",
      "Epoch 4/10, Loss: 2.019683361053467\n",
      "Epoch 5/10, Loss: 1.6033015251159668\n",
      "Epoch 6/10, Loss: 1.812899112701416\n",
      "Epoch 7/10, Loss: 1.6511797904968262\n",
      "Epoch 8/10, Loss: 1.6344441175460815\n",
      "Epoch 9/10, Loss: 1.9293426275253296\n",
      "Epoch 10/10, Loss: 1.7440887689590454\n",
      "Test Accuracy: 19.32%\n",
      "Learning Rate = 0.5 and epoch = 25\n",
      "Epoch 1/25, Loss: 2.5346286296844482\n",
      "Epoch 2/25, Loss: 1.7508553266525269\n",
      "Epoch 3/25, Loss: 1.6801506280899048\n",
      "Epoch 4/25, Loss: 1.6270456314086914\n",
      "Epoch 5/25, Loss: 1.785644769668579\n",
      "Epoch 6/25, Loss: 1.9702941179275513\n",
      "Epoch 7/25, Loss: 1.6226811408996582\n",
      "Epoch 8/25, Loss: 1.6961874961853027\n",
      "Epoch 9/25, Loss: 2.3470163345336914\n",
      "Epoch 10/25, Loss: 72.56266784667969\n",
      "Epoch 11/25, Loss: 223.0096893310547\n",
      "Epoch 12/25, Loss: 70.53620147705078\n",
      "Epoch 13/25, Loss: 19.285886764526367\n",
      "Epoch 14/25, Loss: 7.428539752960205\n",
      "Epoch 15/25, Loss: 3.8824501037597656\n",
      "Epoch 16/25, Loss: 5.816864967346191\n",
      "Epoch 17/25, Loss: 3.552614450454712\n",
      "Epoch 18/25, Loss: 2.2646193504333496\n",
      "Epoch 19/25, Loss: 2.5581696033477783\n",
      "Epoch 20/25, Loss: 2.4178202152252197\n",
      "Epoch 21/25, Loss: 2.1328070163726807\n",
      "Epoch 22/25, Loss: 2.280890941619873\n",
      "Epoch 23/25, Loss: 1.7691186666488647\n",
      "Epoch 24/25, Loss: 2.2156383991241455\n",
      "Epoch 25/25, Loss: 3.2464611530303955\n",
      "Test Accuracy: 20.31%\n",
      "Learning Rate = 0.5 and epoch = 50\n",
      "Epoch 1/50, Loss: 2.257779121398926\n",
      "Epoch 2/50, Loss: 1.7590579986572266\n",
      "Epoch 3/50, Loss: 1.7779818773269653\n",
      "Epoch 4/50, Loss: 1.731738567352295\n",
      "Epoch 5/50, Loss: 1.7558848857879639\n",
      "Epoch 6/50, Loss: 1.8211256265640259\n",
      "Epoch 7/50, Loss: 1.734175682067871\n",
      "Epoch 8/50, Loss: 1.7096549272537231\n",
      "Epoch 9/50, Loss: 2.374920129776001\n",
      "Epoch 10/50, Loss: 1.8848739862442017\n",
      "Epoch 11/50, Loss: 1.7826734781265259\n",
      "Epoch 12/50, Loss: 2.0857903957366943\n",
      "Epoch 13/50, Loss: 483.1683349609375\n",
      "Epoch 14/50, Loss: 146.17091369628906\n",
      "Epoch 15/50, Loss: 14.395015716552734\n",
      "Epoch 16/50, Loss: 19.893810272216797\n",
      "Epoch 17/50, Loss: 8.29981803894043\n",
      "Epoch 18/50, Loss: 3.2319934368133545\n",
      "Epoch 19/50, Loss: 10.64535903930664\n",
      "Epoch 20/50, Loss: 7.094561576843262\n",
      "Epoch 21/50, Loss: 3.0064730644226074\n",
      "Epoch 22/50, Loss: 3.3196260929107666\n",
      "Epoch 23/50, Loss: 2.8561058044433594\n",
      "Epoch 24/50, Loss: 2.0242772102355957\n",
      "Epoch 25/50, Loss: 2.2278618812561035\n",
      "Epoch 26/50, Loss: 2.700387716293335\n",
      "Epoch 27/50, Loss: 2.5914268493652344\n",
      "Epoch 28/50, Loss: 2.157600164413452\n",
      "Epoch 29/50, Loss: 1.7594002485275269\n",
      "Epoch 30/50, Loss: 2.0292718410491943\n",
      "Epoch 31/50, Loss: 1.85488760471344\n",
      "Epoch 32/50, Loss: 1.8826533555984497\n",
      "Epoch 33/50, Loss: 2.0391876697540283\n",
      "Epoch 34/50, Loss: 2.1874032020568848\n",
      "Epoch 35/50, Loss: 1.7598615884780884\n",
      "Epoch 36/50, Loss: 2.174877166748047\n",
      "Epoch 37/50, Loss: 1.9713879823684692\n",
      "Epoch 38/50, Loss: 1.7687819004058838\n",
      "Epoch 39/50, Loss: 2.2800657749176025\n",
      "Epoch 40/50, Loss: 1.7187899351119995\n",
      "Epoch 41/50, Loss: 1.961414098739624\n",
      "Epoch 42/50, Loss: 2.1489219665527344\n",
      "Epoch 43/50, Loss: 2.6106245517730713\n",
      "Epoch 44/50, Loss: 1.8763904571533203\n",
      "Epoch 45/50, Loss: 1.7381869554519653\n",
      "Epoch 46/50, Loss: 1.7464213371276855\n",
      "Epoch 47/50, Loss: 1.9329519271850586\n",
      "Epoch 48/50, Loss: 1.8225080966949463\n",
      "Epoch 49/50, Loss: 1.7757154703140259\n",
      "Epoch 50/50, Loss: 1.7536203861236572\n",
      "Test Accuracy: 19.74%\n",
      "Learning Rate = 0.1 and epoch = 5\n",
      "Epoch 1/5, Loss: 1.5968363285064697\n",
      "Epoch 2/5, Loss: 1.6249525547027588\n",
      "Epoch 3/5, Loss: 1.6301840543746948\n",
      "Epoch 4/5, Loss: 1.6367251873016357\n",
      "Epoch 5/5, Loss: 1.620859980583191\n",
      "Test Accuracy: 22.16%\n",
      "Learning Rate = 0.1 and epoch = 10\n",
      "Epoch 1/10, Loss: 1.6446987390518188\n",
      "Epoch 2/10, Loss: 1.6620163917541504\n",
      "Epoch 3/10, Loss: 1.6075787544250488\n",
      "Epoch 4/10, Loss: 1.6250066757202148\n",
      "Epoch 5/10, Loss: 1.6233257055282593\n",
      "Epoch 6/10, Loss: 1.6362744569778442\n",
      "Epoch 7/10, Loss: 1.586012363433838\n",
      "Epoch 8/10, Loss: 1.636799693107605\n",
      "Epoch 9/10, Loss: 1.630731225013733\n",
      "Epoch 10/10, Loss: 1.6234074831008911\n",
      "Test Accuracy: 20.03%\n",
      "Learning Rate = 0.1 and epoch = 25\n",
      "Epoch 1/25, Loss: 1.668981909751892\n",
      "Epoch 2/25, Loss: 1.6325960159301758\n",
      "Epoch 3/25, Loss: 1.5987130403518677\n",
      "Epoch 4/25, Loss: 1.6594713926315308\n",
      "Epoch 5/25, Loss: 1.7503219842910767\n",
      "Epoch 6/25, Loss: 1.6319925785064697\n",
      "Epoch 7/25, Loss: 1.604012370109558\n",
      "Epoch 8/25, Loss: 1.5969550609588623\n",
      "Epoch 9/25, Loss: 1.5879237651824951\n",
      "Epoch 10/25, Loss: 1.7128245830535889\n",
      "Epoch 11/25, Loss: 1.5970853567123413\n",
      "Epoch 12/25, Loss: 1.6091781854629517\n",
      "Epoch 13/25, Loss: 1.6856348514556885\n",
      "Epoch 14/25, Loss: 1.5856760740280151\n",
      "Epoch 15/25, Loss: 1.6298332214355469\n",
      "Epoch 16/25, Loss: 1.6589689254760742\n",
      "Epoch 17/25, Loss: 2.082798719406128\n",
      "Epoch 18/25, Loss: 1.644486665725708\n",
      "Epoch 19/25, Loss: 1.648494839668274\n",
      "Epoch 20/25, Loss: 1.6273521184921265\n",
      "Epoch 21/25, Loss: 1.6795474290847778\n",
      "Epoch 22/25, Loss: 1.6280418634414673\n",
      "Epoch 23/25, Loss: 1.5777767896652222\n",
      "Epoch 24/25, Loss: 1.5868593454360962\n",
      "Epoch 25/25, Loss: 1.6074262857437134\n",
      "Test Accuracy: 19.89%\n",
      "Learning Rate = 0.1 and epoch = 50\n",
      "Epoch 1/50, Loss: 1.579039454460144\n",
      "Epoch 2/50, Loss: 1.6124813556671143\n",
      "Epoch 3/50, Loss: 1.6309964656829834\n",
      "Epoch 4/50, Loss: 1.6199537515640259\n",
      "Epoch 5/50, Loss: 1.592195987701416\n",
      "Epoch 6/50, Loss: 1.6478886604309082\n",
      "Epoch 7/50, Loss: 1.6425474882125854\n",
      "Epoch 8/50, Loss: 1.574358582496643\n",
      "Epoch 9/50, Loss: 1.6060705184936523\n",
      "Epoch 10/50, Loss: 1.614946961402893\n",
      "Epoch 11/50, Loss: 1.7764217853546143\n",
      "Epoch 12/50, Loss: 1.5852925777435303\n",
      "Epoch 13/50, Loss: 1.6387193202972412\n",
      "Epoch 14/50, Loss: 1.674954891204834\n",
      "Epoch 15/50, Loss: 1.7214537858963013\n",
      "Epoch 16/50, Loss: 1.667434573173523\n",
      "Epoch 17/50, Loss: 1.6008543968200684\n",
      "Epoch 18/50, Loss: 1.7232569456100464\n",
      "Epoch 19/50, Loss: 1.7069897651672363\n",
      "Epoch 20/50, Loss: 1.7193973064422607\n",
      "Epoch 21/50, Loss: 1.6375019550323486\n",
      "Epoch 22/50, Loss: 1.664553165435791\n",
      "Epoch 23/50, Loss: 1.609689712524414\n",
      "Epoch 24/50, Loss: 1.6509242057800293\n",
      "Epoch 25/50, Loss: 1.637728214263916\n",
      "Epoch 26/50, Loss: 1.6788756847381592\n",
      "Epoch 27/50, Loss: 1.6635938882827759\n",
      "Epoch 28/50, Loss: 1.635191798210144\n",
      "Epoch 29/50, Loss: 1.6190237998962402\n",
      "Epoch 30/50, Loss: 1.5510958433151245\n",
      "Epoch 31/50, Loss: 1.576220989227295\n",
      "Epoch 32/50, Loss: 1.7317615747451782\n",
      "Epoch 33/50, Loss: 1.7630020380020142\n",
      "Epoch 34/50, Loss: 1.7340173721313477\n",
      "Epoch 35/50, Loss: 1.5992419719696045\n",
      "Epoch 36/50, Loss: 1.6207858324050903\n",
      "Epoch 37/50, Loss: 1.5529087781906128\n",
      "Epoch 38/50, Loss: 2.2340376377105713\n",
      "Epoch 39/50, Loss: 1.6490092277526855\n",
      "Epoch 40/50, Loss: 1.6850966215133667\n",
      "Epoch 41/50, Loss: 1.62080717086792\n",
      "Epoch 42/50, Loss: 1.6769016981124878\n",
      "Epoch 43/50, Loss: 1.609264850616455\n",
      "Epoch 44/50, Loss: 1.5496574640274048\n",
      "Epoch 45/50, Loss: 1.4997334480285645\n",
      "Epoch 46/50, Loss: 1.7062323093414307\n",
      "Epoch 47/50, Loss: 1.5999611616134644\n",
      "Epoch 48/50, Loss: 1.6251554489135742\n",
      "Epoch 49/50, Loss: 1.6471163034439087\n",
      "Epoch 50/50, Loss: 1.689031958580017\n",
      "Test Accuracy: 20.88%\n",
      "Learning Rate = 0.05 and epoch = 5\n",
      "Epoch 1/5, Loss: 1.6414238214492798\n",
      "Epoch 2/5, Loss: 1.6110568046569824\n",
      "Epoch 3/5, Loss: 1.593668818473816\n",
      "Epoch 4/5, Loss: 1.617572546005249\n",
      "Epoch 5/5, Loss: 1.6126365661621094\n",
      "Test Accuracy: 21.88%\n",
      "Learning Rate = 0.05 and epoch = 10\n",
      "Epoch 1/10, Loss: 1.6084169149398804\n",
      "Epoch 2/10, Loss: 1.6115785837173462\n",
      "Epoch 3/10, Loss: 1.633818507194519\n",
      "Epoch 4/10, Loss: 1.6355870962142944\n",
      "Epoch 5/10, Loss: 1.6185033321380615\n",
      "Epoch 6/10, Loss: 1.604546070098877\n",
      "Epoch 7/10, Loss: 1.6051768064498901\n",
      "Epoch 8/10, Loss: 1.6117291450500488\n",
      "Epoch 9/10, Loss: 1.6162750720977783\n",
      "Epoch 10/10, Loss: 1.6224662065505981\n",
      "Test Accuracy: 20.31%\n",
      "Learning Rate = 0.05 and epoch = 25\n",
      "Epoch 1/25, Loss: 1.6264867782592773\n",
      "Epoch 2/25, Loss: 1.614046573638916\n",
      "Epoch 3/25, Loss: 1.5654051303863525\n",
      "Epoch 4/25, Loss: 1.6155385971069336\n",
      "Epoch 5/25, Loss: 1.6118005514144897\n",
      "Epoch 6/25, Loss: 1.6162950992584229\n",
      "Epoch 7/25, Loss: 1.6218899488449097\n",
      "Epoch 8/25, Loss: 1.626413345336914\n",
      "Epoch 9/25, Loss: 1.6331279277801514\n",
      "Epoch 10/25, Loss: 1.64761483669281\n",
      "Epoch 11/25, Loss: 1.5860339403152466\n",
      "Epoch 12/25, Loss: 1.5912302732467651\n",
      "Epoch 13/25, Loss: 1.6048083305358887\n",
      "Epoch 14/25, Loss: 1.5803178548812866\n",
      "Epoch 15/25, Loss: 1.5617163181304932\n",
      "Epoch 16/25, Loss: 1.720089077949524\n",
      "Epoch 17/25, Loss: 1.594286561012268\n",
      "Epoch 18/25, Loss: 1.580553650856018\n",
      "Epoch 19/25, Loss: 1.6457922458648682\n",
      "Epoch 20/25, Loss: 1.5404725074768066\n",
      "Epoch 21/25, Loss: 1.6331541538238525\n",
      "Epoch 22/25, Loss: 1.5077931880950928\n",
      "Epoch 23/25, Loss: 1.478930115699768\n",
      "Epoch 24/25, Loss: 1.4457590579986572\n",
      "Epoch 25/25, Loss: 1.5617196559906006\n",
      "Test Accuracy: 24.86%\n",
      "Learning Rate = 0.05 and epoch = 50\n",
      "Epoch 1/50, Loss: 1.619046688079834\n",
      "Epoch 2/50, Loss: 1.6199480295181274\n",
      "Epoch 3/50, Loss: 1.6288878917694092\n",
      "Epoch 4/50, Loss: 1.631517767906189\n",
      "Epoch 5/50, Loss: 1.6291707754135132\n",
      "Epoch 6/50, Loss: 1.60906183719635\n",
      "Epoch 7/50, Loss: 1.6093692779541016\n",
      "Epoch 8/50, Loss: 1.5731232166290283\n",
      "Epoch 9/50, Loss: 1.5447416305541992\n",
      "Epoch 10/50, Loss: 1.5687391757965088\n",
      "Epoch 11/50, Loss: 1.5629380941390991\n",
      "Epoch 12/50, Loss: 1.5527442693710327\n",
      "Epoch 13/50, Loss: 1.5729697942733765\n",
      "Epoch 14/50, Loss: 1.6569485664367676\n",
      "Epoch 15/50, Loss: 1.5617433786392212\n",
      "Epoch 16/50, Loss: 1.5476142168045044\n",
      "Epoch 17/50, Loss: 1.594669222831726\n",
      "Epoch 18/50, Loss: 1.6026643514633179\n",
      "Epoch 19/50, Loss: 1.5415129661560059\n",
      "Epoch 20/50, Loss: 1.5044432878494263\n",
      "Epoch 21/50, Loss: 1.5115711688995361\n",
      "Epoch 22/50, Loss: 1.555732250213623\n",
      "Epoch 23/50, Loss: 1.5002658367156982\n",
      "Epoch 24/50, Loss: 1.4375165700912476\n",
      "Epoch 25/50, Loss: 1.5106899738311768\n",
      "Epoch 26/50, Loss: 1.5126590728759766\n",
      "Epoch 27/50, Loss: 1.4253880977630615\n",
      "Epoch 28/50, Loss: 1.5268235206604004\n",
      "Epoch 29/50, Loss: 1.5180189609527588\n",
      "Epoch 30/50, Loss: 1.4145816564559937\n",
      "Epoch 31/50, Loss: 1.4580330848693848\n",
      "Epoch 32/50, Loss: 1.3996164798736572\n",
      "Epoch 33/50, Loss: 1.248605728149414\n",
      "Epoch 34/50, Loss: 1.3341686725616455\n",
      "Epoch 35/50, Loss: 1.3565328121185303\n",
      "Epoch 36/50, Loss: 1.1222209930419922\n",
      "Epoch 37/50, Loss: 1.484821081161499\n",
      "Epoch 38/50, Loss: 1.320202350616455\n",
      "Epoch 39/50, Loss: 1.4274928569793701\n",
      "Epoch 40/50, Loss: 1.2075878381729126\n",
      "Epoch 41/50, Loss: 1.446262240409851\n",
      "Epoch 42/50, Loss: 1.2634990215301514\n",
      "Epoch 43/50, Loss: 1.2692149877548218\n",
      "Epoch 44/50, Loss: 1.2622096538543701\n",
      "Epoch 45/50, Loss: 1.3287204504013062\n",
      "Epoch 46/50, Loss: 1.2371797561645508\n",
      "Epoch 47/50, Loss: 1.1190496683120728\n",
      "Epoch 48/50, Loss: 1.1221610307693481\n",
      "Epoch 49/50, Loss: 1.159774661064148\n",
      "Epoch 50/50, Loss: 0.9066645503044128\n",
      "Test Accuracy: 30.54%\n",
      "Learning Rate = 0.02 and epoch = 5\n",
      "Epoch 1/5, Loss: 1.622950553894043\n",
      "Epoch 2/5, Loss: 1.6045722961425781\n",
      "Epoch 3/5, Loss: 1.6196656227111816\n",
      "Epoch 4/5, Loss: 1.5829766988754272\n",
      "Epoch 5/5, Loss: 1.5844807624816895\n",
      "Test Accuracy: 22.30%\n",
      "Learning Rate = 0.02 and epoch = 10\n",
      "Epoch 1/10, Loss: 1.622037649154663\n",
      "Epoch 2/10, Loss: 1.6192795038223267\n",
      "Epoch 3/10, Loss: 1.6402047872543335\n",
      "Epoch 4/10, Loss: 1.645124912261963\n",
      "Epoch 5/10, Loss: 1.5484678745269775\n",
      "Epoch 6/10, Loss: 1.5525331497192383\n",
      "Epoch 7/10, Loss: 1.5454238653182983\n",
      "Epoch 8/10, Loss: 1.564107894897461\n",
      "Epoch 9/10, Loss: 1.5792760848999023\n",
      "Epoch 10/10, Loss: 1.6011719703674316\n",
      "Test Accuracy: 27.56%\n",
      "Learning Rate = 0.02 and epoch = 25\n",
      "Epoch 1/25, Loss: 1.6156795024871826\n",
      "Epoch 2/25, Loss: 1.6013661623001099\n",
      "Epoch 3/25, Loss: 1.6053440570831299\n",
      "Epoch 4/25, Loss: 1.609477162361145\n",
      "Epoch 5/25, Loss: 1.6131490468978882\n",
      "Epoch 6/25, Loss: 1.616779088973999\n",
      "Epoch 7/25, Loss: 1.6044020652770996\n",
      "Epoch 8/25, Loss: 1.5206894874572754\n",
      "Epoch 9/25, Loss: 1.4397501945495605\n",
      "Epoch 10/25, Loss: 1.5511404275894165\n",
      "Epoch 11/25, Loss: 1.5099610090255737\n",
      "Epoch 12/25, Loss: 1.5159999132156372\n",
      "Epoch 13/25, Loss: 1.4627892971038818\n",
      "Epoch 14/25, Loss: 1.3376553058624268\n",
      "Epoch 15/25, Loss: 1.336305022239685\n",
      "Epoch 16/25, Loss: 1.1944072246551514\n",
      "Epoch 17/25, Loss: 1.2882460355758667\n",
      "Epoch 18/25, Loss: 1.2946321964263916\n",
      "Epoch 19/25, Loss: 1.178611159324646\n",
      "Epoch 20/25, Loss: 1.1553701162338257\n",
      "Epoch 21/25, Loss: 1.3797868490219116\n",
      "Epoch 22/25, Loss: 0.9270273447036743\n",
      "Epoch 23/25, Loss: 1.0773162841796875\n",
      "Epoch 24/25, Loss: 0.9667372703552246\n",
      "Epoch 25/25, Loss: 1.1683130264282227\n",
      "Test Accuracy: 38.92%\n",
      "Learning Rate = 0.02 and epoch = 50\n",
      "Epoch 1/50, Loss: 1.6018474102020264\n",
      "Epoch 2/50, Loss: 1.6086583137512207\n",
      "Epoch 3/50, Loss: 1.5838814973831177\n",
      "Epoch 4/50, Loss: 1.6344842910766602\n",
      "Epoch 5/50, Loss: 1.635159969329834\n",
      "Epoch 6/50, Loss: 1.6143412590026855\n",
      "Epoch 7/50, Loss: 1.5780819654464722\n",
      "Epoch 8/50, Loss: 1.5347033739089966\n",
      "Epoch 9/50, Loss: 1.582667350769043\n",
      "Epoch 10/50, Loss: 1.4982601404190063\n",
      "Epoch 11/50, Loss: 1.4910314083099365\n",
      "Epoch 12/50, Loss: 1.5064070224761963\n",
      "Epoch 13/50, Loss: 1.3636189699172974\n",
      "Epoch 14/50, Loss: 1.4222618341445923\n",
      "Epoch 15/50, Loss: 1.448500394821167\n",
      "Epoch 16/50, Loss: 1.1661319732666016\n",
      "Epoch 17/50, Loss: 1.4743614196777344\n",
      "Epoch 18/50, Loss: 1.2956305742263794\n",
      "Epoch 19/50, Loss: 1.1410447359085083\n",
      "Epoch 20/50, Loss: 1.4515820741653442\n",
      "Epoch 21/50, Loss: 1.1745060682296753\n",
      "Epoch 22/50, Loss: 1.2543377876281738\n",
      "Epoch 23/50, Loss: 1.159717321395874\n",
      "Epoch 24/50, Loss: 1.1452842950820923\n",
      "Epoch 25/50, Loss: 1.2620056867599487\n",
      "Epoch 26/50, Loss: 1.2369691133499146\n",
      "Epoch 27/50, Loss: 0.9680573344230652\n",
      "Epoch 28/50, Loss: 1.0616594552993774\n",
      "Epoch 29/50, Loss: 1.2224044799804688\n",
      "Epoch 30/50, Loss: 0.7191481590270996\n",
      "Epoch 31/50, Loss: 1.0865659713745117\n",
      "Epoch 32/50, Loss: 0.7874277234077454\n",
      "Epoch 33/50, Loss: 0.669447124004364\n",
      "Epoch 34/50, Loss: 0.6562932133674622\n",
      "Epoch 35/50, Loss: 0.8727276921272278\n",
      "Epoch 36/50, Loss: 0.7852630019187927\n",
      "Epoch 37/50, Loss: 0.8142607808113098\n",
      "Epoch 38/50, Loss: 0.6232120394706726\n",
      "Epoch 39/50, Loss: 0.5710102319717407\n",
      "Epoch 40/50, Loss: 0.7209147214889526\n",
      "Epoch 41/50, Loss: 0.5449436902999878\n",
      "Epoch 42/50, Loss: 0.5990759134292603\n",
      "Epoch 43/50, Loss: 0.6064249873161316\n",
      "Epoch 44/50, Loss: 0.6521008014678955\n",
      "Epoch 45/50, Loss: 0.7257164716720581\n",
      "Epoch 46/50, Loss: 0.5556702613830566\n",
      "Epoch 47/50, Loss: 0.3399982452392578\n",
      "Epoch 48/50, Loss: 0.38223135471343994\n",
      "Epoch 49/50, Loss: 0.5645172595977783\n",
      "Epoch 50/50, Loss: 0.6864009499549866\n",
      "Test Accuracy: 47.73%\n",
      "Learning Rate = 0.01 and epoch = 5\n",
      "Epoch 1/5, Loss: 1.6248363256454468\n",
      "Epoch 2/5, Loss: 1.6084505319595337\n",
      "Epoch 3/5, Loss: 1.5974400043487549\n",
      "Epoch 4/5, Loss: 1.546247959136963\n",
      "Epoch 5/5, Loss: 1.617864727973938\n",
      "Test Accuracy: 26.70%\n",
      "Learning Rate = 0.01 and epoch = 10\n",
      "Epoch 1/10, Loss: 1.6154714822769165\n",
      "Epoch 2/10, Loss: 1.6191813945770264\n",
      "Epoch 3/10, Loss: 1.6398112773895264\n",
      "Epoch 4/10, Loss: 1.5635353326797485\n",
      "Epoch 5/10, Loss: 1.5319457054138184\n",
      "Epoch 6/10, Loss: 1.507031798362732\n",
      "Epoch 7/10, Loss: 1.4157476425170898\n",
      "Epoch 8/10, Loss: 1.5429214239120483\n",
      "Epoch 9/10, Loss: 1.444520354270935\n",
      "Epoch 10/10, Loss: 1.4248234033584595\n",
      "Test Accuracy: 32.95%\n",
      "Learning Rate = 0.01 and epoch = 25\n",
      "Epoch 1/25, Loss: 1.5886681079864502\n",
      "Epoch 2/25, Loss: 1.6298587322235107\n",
      "Epoch 3/25, Loss: 1.6508033275604248\n",
      "Epoch 4/25, Loss: 1.56058931350708\n",
      "Epoch 5/25, Loss: 1.621270775794983\n",
      "Epoch 6/25, Loss: 1.6372323036193848\n",
      "Epoch 7/25, Loss: 1.6193796396255493\n",
      "Epoch 8/25, Loss: 1.419748306274414\n",
      "Epoch 9/25, Loss: 1.5669875144958496\n",
      "Epoch 10/25, Loss: 1.4464354515075684\n",
      "Epoch 11/25, Loss: 1.4026120901107788\n",
      "Epoch 12/25, Loss: 1.255134105682373\n",
      "Epoch 13/25, Loss: 1.1267918348312378\n",
      "Epoch 14/25, Loss: 1.3264880180358887\n",
      "Epoch 15/25, Loss: 1.1366581916809082\n",
      "Epoch 16/25, Loss: 1.1310175657272339\n",
      "Epoch 17/25, Loss: 0.9753162264823914\n",
      "Epoch 18/25, Loss: 0.9762277603149414\n",
      "Epoch 19/25, Loss: 0.8178613781929016\n",
      "Epoch 20/25, Loss: 0.932921290397644\n",
      "Epoch 21/25, Loss: 0.7558362483978271\n",
      "Epoch 22/25, Loss: 0.8398375511169434\n",
      "Epoch 23/25, Loss: 0.687566339969635\n",
      "Epoch 24/25, Loss: 0.7072195410728455\n",
      "Epoch 25/25, Loss: 0.604251503944397\n",
      "Test Accuracy: 44.89%\n",
      "Learning Rate = 0.01 and epoch = 50\n",
      "Epoch 1/50, Loss: 1.6010141372680664\n",
      "Epoch 2/50, Loss: 1.6095575094223022\n",
      "Epoch 3/50, Loss: 1.5750292539596558\n",
      "Epoch 4/50, Loss: 1.610586166381836\n",
      "Epoch 5/50, Loss: 1.5327273607254028\n",
      "Epoch 6/50, Loss: 1.5071898698806763\n",
      "Epoch 7/50, Loss: 1.5652177333831787\n",
      "Epoch 8/50, Loss: 1.5203009843826294\n",
      "Epoch 9/50, Loss: 1.4157294034957886\n",
      "Epoch 10/50, Loss: 1.444863200187683\n",
      "Epoch 11/50, Loss: 1.2146408557891846\n",
      "Epoch 12/50, Loss: 1.2200435400009155\n",
      "Epoch 13/50, Loss: 1.387183666229248\n",
      "Epoch 14/50, Loss: 1.2121648788452148\n",
      "Epoch 15/50, Loss: 1.0952883958816528\n",
      "Epoch 16/50, Loss: 0.9792343378067017\n",
      "Epoch 17/50, Loss: 0.9635694622993469\n",
      "Epoch 18/50, Loss: 0.9809385538101196\n",
      "Epoch 19/50, Loss: 0.8049604892730713\n",
      "Epoch 20/50, Loss: 0.8914662599563599\n",
      "Epoch 21/50, Loss: 0.8064332604408264\n",
      "Epoch 22/50, Loss: 0.9272564053535461\n",
      "Epoch 23/50, Loss: 0.5736415386199951\n",
      "Epoch 24/50, Loss: 0.7483001351356506\n",
      "Epoch 25/50, Loss: 0.9256458282470703\n",
      "Epoch 26/50, Loss: 0.6140347719192505\n",
      "Epoch 27/50, Loss: 0.6530041694641113\n",
      "Epoch 28/50, Loss: 0.3072689175605774\n",
      "Epoch 29/50, Loss: 0.5173848867416382\n",
      "Epoch 30/50, Loss: 0.6493118405342102\n",
      "Epoch 31/50, Loss: 0.5060706734657288\n",
      "Epoch 32/50, Loss: 0.7099989056587219\n",
      "Epoch 33/50, Loss: 0.6555928587913513\n",
      "Epoch 34/50, Loss: 0.3662617802619934\n",
      "Epoch 35/50, Loss: 0.5057587623596191\n",
      "Epoch 36/50, Loss: 0.4531807005405426\n",
      "Epoch 37/50, Loss: 0.4785507321357727\n",
      "Epoch 38/50, Loss: 0.32056304812431335\n",
      "Epoch 39/50, Loss: 0.44489482045173645\n",
      "Epoch 40/50, Loss: 0.4895339906215668\n",
      "Epoch 41/50, Loss: 0.4176782965660095\n",
      "Epoch 42/50, Loss: 0.3930838406085968\n",
      "Epoch 43/50, Loss: 0.33232468366622925\n",
      "Epoch 44/50, Loss: 0.1184895858168602\n",
      "Epoch 45/50, Loss: 0.4112829864025116\n",
      "Epoch 46/50, Loss: 0.1577215939760208\n",
      "Epoch 47/50, Loss: 0.23950077593326569\n",
      "Epoch 48/50, Loss: 0.4211404323577881\n",
      "Epoch 49/50, Loss: 0.19091889262199402\n",
      "Epoch 50/50, Loss: 0.34071114659309387\n",
      "Test Accuracy: 50.99%\n"
     ]
    }
   ],
   "source": [
    "for i in [0.05, 0.02, 0.01, 0.005, 0.001]:\n",
    "    for e in [5, 10, 25, 50]:\n",
    "        print(f\"Learning Rate = {i} and epoch = {e}\")\n",
    "        num_classes = 5 # setting final output class\n",
    "        model = EEGAutoencoderClassifier(num_classes).to(device) \n",
    "        criterion = nn.NLLLoss() # Use NLLLoss function to optimize\n",
    "        optimizer = optim.Adam(model.parameters(), i) # Setting parameters learning rate\n",
    "        \n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "\n",
    "        for epoch in range(e):\n",
    "            model.train()\n",
    "            for data, labels in train_loader: \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(data)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            print(f'Epoch {epoch + 1}/{e}, Loss: {loss.item()}')\n",
    "            \n",
    "        \n",
    "        model.eval() # Evaluate your model\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, labels in test_loader:\n",
    "                outputs = model(data)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = correct / total\n",
    "        print(f'Test Accuracy: {accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
